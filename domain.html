<!DOCTYPE HTML>
<!--
	Spectral by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Domain - Project Sherlock</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Page Wrapper -->
			<div id="page-wrapper">

				<!-- Header -->
					<header id="header">
						<h1><a href="index.html">Project Sherlock</a></h1>
						<nav id="nav">
							<ul>
								<li class="special">
									<a href="#menu" class="menuToggle"><span>Menu</span></a>
									<div id="menu">
										<ul>
											<li><a href="index.html">Home</a></li>
											<li><a href="domain.html">Domain</a></li>
											<li><a href="milestones.html">Milestones</a></li>
											<li><a href="documents.html">Documents</a></li>
											<!-- <li><a href="slides.html">Slides</a></li> -->
											<li><a href="aboutus.html">About us</a></li>
											<li><a href="contactus.html">Contact us</a></li>
										</ul>
									</div>
								</li>
							</ul>
						</nav>
					</header>

				<!-- Main -->
					<article id="main">
						<header>
							<h2>Domain</h2>
							<p>Details of the research project.</p>
						</header>
						<section class="wrapper style5">
							<div class="inner">

								<section>
									<h4>Literature Survery</h4>
									<p>
										Fraudsters do not use the same techniques over and over. They are updated about fraud detection mechanisms. When their old hacks fail, they will use new methods. This cannot be predicted using simple machine learning models which are based on trained data. This is where Markov modelling comes in. This model assumes that future states depend only on the present state and not on the sequence of events that preceded it. Hence, the model will use real time data to be updated and to learn about new mechanisms of frauds.
										<br/><br/>
										The fraud detection solution uses the above stated Markov modelling, generic rules, fraud scoring and data clustering mechanisms. WSO2 stream processor is an open source stream processing platform. It has batch, real-time, predictive analytics capabilities. This can ingest data from Kafka, HTTP requests and message brokers. The solution covers big data and internet of things projects since it treats millions of events per second.
										<br/><br/>
										X13-VSA is a voice lie detector application. Most likely voice based portable polygraph application which is already quite popular commercial lie detector tool. This is developed by X13 Team. This application analyzes the people's voice and the stress level and verify the truth. It is called VSA (Voice Stress Analyzer) based lie detector, this method become popular since 1970 and widely use on secret government organization, insurance companies & police department. Since this application is a software application 98% cost effective according to their official website.
									</p>

									<h4>Methodology</h4>
									<p>
										Our solution is mainly focused for Financial Institutes. The aim of this system is to analyze the human facial expressions, behavioral patterns, voice patterns, background environment and human interaction with the environment and identify the possible anomalies. 
										<br/><br/>
										<b>Facial Component</b>
										<br/><br/>
										•	Facial patterns using camera or Kinect like sense detection camera. 
										•	Human behavioral patterns using CCTVs stream. 
										•	Voice and Speaking patterns using Microphone. 
										•	Suspicious transactions using Transaction data/ history and environment/ social factors. 
										<br/><br/>
										Humans can identify or inspect, whether a user is trying to do fraudulent activity or trying to lie by looking at the person. On average people don’t do much better than a coin flip.
										But by using machine learning techniques and algorithms we can automate and increase the accuracy of the detection of fraudulent activities and identify patterns that people normally use for doing fraudulent activities.
										To get the facial data we can use a Kinect camera/ sensor that aim towards the customer’s (user’s) face.

										Using the camera, we can detect
										·         Expressions and Micro-Expressions.
										·         Emotions.
										·         Eye movements.
										·         Nose touching and mouth covering.
										·         Sweating.
										These are some psychological effects when someone tries to hide their true intentions from others or simply when someone tries to do a fraudulent activity.
										By using these data, we can predict or assume whether this user is suspicious or not, with some confidence level. With information that cashier or officer who is doing the transaction can give more attention to the user(customer) and probably reduce or prevent fraudulent activities from happening.
										<br/>
											<br/><br/>
										<b>Body Language Component</b>
										<br/><br/>
										Since the past humans have been able to identify fraudulent activities by looking at another person's body-language and gestures, there are highly paid individuals whose job is to find out those abnormal behavioral patterns. So, in this research part we are trying to automate this process by developing a software solution to identify frauds with human body-languages and abnormal movements using CCTV camera footage. In this research we have decided to use deep learning approach since there might be some social cues we might miss if go with labeling each behavior.
There are three main parts to this sub component
1.       Identifying anomalies.
2.       Creating a risk profile.
3.       Tracking between multiple cameras.
By using this method, we will mainly categorize the persons in the vicinity according to a risk level and those who are with a higher risk level will be analyzed thoroughly by the other components of this research. By doing this we are saving the computational power wastage of analyzing every single person in detail who enters the vicinity.
									</p>
										<br/><br/>
										<b>Voice Component</b>
										<br/><br/>
									<p>
									Like human able identify frauds, lies, deceits or scams by another person’s voice or speaking patterns This product is able to identify lies and fraudulent activities. Mainly there are two types of methods to identify frauds using the voice. Those types are, Language Based & Sounds Based. Since language-based type depend on specific language it cannot be implemented for Sri Lanka, because identifying meaning of Sinhala speeches are quite bigger domain. So, the target is to identify deceits with sounds based.
									<p/>
									<p>
										Sound based frauds detecting also focused on key points and rules based (Based on psychological studies) Key points of sound-based frauds detecting are changes of breathing, changes voice frequencies, stammer, stutter, frequently pausing, repeating,volume and the tone of voice, vocal expression of emotions (screaming, yelling, whining and crying) etc.
Since this product will be working on crowded environment before analyzing the sound clip we have to preprocess the sound clip by cancelling the background noises and identify isolated customer voice with fine details of the sound. Then trained neural network model able to analyze the sound clip and able to detect lies, this part of the solution can state a prediction for suspicion of certain customer by their voice.  Overall flow shown in Figure 4: Voice Capture
									</p>
										<br/><br/>
										<b>Transaction Component</b>
										<br/><br/>
									<p>
										To identify the transactions of a fraudster, a trained machine learning model is needed. Training this model is done by using data sets which are labelled. To select a suitable machine learning algorithm, we have to test by trying out different algorithms. After training the model, it is used by the front end angular component to predict the reliability of a transaction.

As the first step, it is necessary to find a suitable dataset to train the transaction model. It is very rare to find actual transaction details online because of the security and confidentiality reasons. One actual dataset available is the credit card fraud detection data set in kaggle. [10] But as the description of the dataset say, it is a set of anonymized transactions. Because of that, there are no column descriptions for the dataset. This does not matter when the machine learning model is trained. But when a real world scenario is applied to this model, we can not determine which data we have to supply to the model to get a prediction. Because of that reason, we have used a synthetic financial dataset to detect fraudulent transactions. [11] It has generated the transaction using a simulator called PaySim. PaySim uses aggregated data from the private dataset to generate a synthetic dataset that resembles the normal operation of transactions and injects malicious behaviour to later evaluate the performance of fraud detection methods.

The main problem in a fraudulent transaction data set is it is extremely unbalanced. When there are 284315 number of genuine transactions in the set, there are only 492 fraudulent transactions. This leads to a bias of the classification model. To overcome and unbalanced dataset, techniques can be used ie: oversampling, undersampling, SMOTE (Synthetic Minority Oversampling Technique).  SMOTE randomly creates synthetic records to oversample the dataset hence balancing the fraudulent and genuine transaction record numbers.

For the training of the machine learning model, logistic regression algorithm was used. Logistic regression is mostly used for classification problems ie: final oupt is a Yes or No. In this case, Fraudulent or Genuine will be the output.

After training the model, there should be a way to persist the model for future use without having to retrain. A package called Joblib is used to do this task. joblib.dump persist an arbitrary Python object into one file. After dumping the model, it can be hosted in an api using flask (exposing the endpoint).
access from frontend
									</p><br/><br/>

									<hr />
									</section>
					</article>

				<!-- Footer -->
					<footer id="footer">
						<ul class="icons">
							<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
							<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
							<li><a href="#" class="icon brands fa-dribbble"><span class="label">Dribbble</span></a></li>
							<li><a href="#" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
						</ul>
						<ul class="copyright">
							<li>&copy; Untitled</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						</ul>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>