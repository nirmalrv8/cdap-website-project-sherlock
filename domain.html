<!DOCTYPE HTML>
<!--
	Spectral by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Domain - Project Sherlock</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">		

				<div class="topnav">
						<!-- <a href="#menu"><span>Menu</span></a> -->
						<a href="index.html">Home</a>
						<a href="domain.html" class="active">Domain</a>
						<a href="milestones.html">Milestones</a>
						<a href="documents.html">Documents</a>
						<!-- <li><a href="slides.html">Slides</a></li> -->
						<a href="aboutus.html" >About us</a>
						<a href="contactus.html">Contact us</a>
				</div>		

				<!-- Main -->
					<article id="main">
						<header>
							<h2>Domain</h2>
							<p>Details of the research project.</p>
						</header>
						<section class="wrapper style5">
							<div class="inner">

								<section>
									<h4>Literature Survery</h4>
									<p>
										Fraudsters do not use the same techniques over and over. They are updated about fraud detection mechanisms. When their old hacks fail, they will use new methods. This cannot be predicted using simple machine learning models which are based on trained data. This is where Markov modelling comes in. This model assumes that future states depend only on the present state and not on the sequence of events that preceded it. Hence, the model will use real time data to be updated and to learn about new mechanisms of frauds.
										<br/><br/>
										The fraud detection solution uses the above stated Markov modelling, generic rules, fraud scoring and data clustering mechanisms. WSO2 stream processor is an open source stream processing platform. It has batch, real-time, predictive analytics capabilities. This can ingest data from Kafka, HTTP requests and message brokers. The solution covers big data and internet of things projects since it treats millions of events per second.
										<br/><br/>
										X13-VSA is a voice lie detector application. Most likely voice based portable polygraph application which is already quite popular commercial lie detector tool. This is developed by X13 Team. This application analyzes the people's voice and the stress level and verify the truth. It is called VSA (Voice Stress Analyzer) based lie detector, this method become popular since 1970 and widely use on secret government organization, insurance companies & police department. Since this application is a software application 98% cost effective according to their official website.
									</p>

									<h4>Research Gap</h4>
									<p>Even though there are research attempts on fraudulent transactions, there is no complete solution for a banking environment. The specialty of our product is that, this consists of four modules. Facial, behavioral, vocal and transactional modules give a complete analysis of the whole banking scenario. Without focusing on one component, we can get all these four weights into account before determining whether there is going to be a fraud or not.</p>

									<h4>Research Problem</h4>
									<p>In the transaction component, what we are building is a machine learning model based on a data set. In this research area, the main problem is that most people can not find a real data set. Because transactional data are sensitive and private, most banks do not prefer to give out data sets even for research purposes. In all the existing research attempts, this is a main problem to be addressed.
</p>

									<h4>Research Objectives</h4>
									<p>Our main objective of this research is to detect a fraud as early as possible. For that, we need a transaction module which should be efficient and accurate in predicting frauds. 

As stated above, one of the most challenging parts of the transaction module is finding a data set. It should be a valid data set which gives crucial details of transactions, while giving a good number of transaction entries. After finding a dataset, we get the challenge of preprocessing the data. Before feeding the data to the machine learning model, there should be a certain format to the data.

A suitable algorithm for the machine learning model is required to train the model using the acquired data set. This algorithm should be efficient in predicting and learning. There are  lots of machine learning algorithms that can be used for classification problems. But we need to  try many of them to find what is the best option for our problem.

Finally, a system design that will be fast and accurate is needed to contain this trained model. The information flowing of the system should be simple yet efficient.
</p>

									
									<h4>Methodology</h4>
									<p>
										Our solution is mainly focused for Financial Institutes. The aim of this system is to analyze the human facial expressions, behavioral patterns, voice patterns, background environment and human interaction with the environment and identify the possible anomalies. 
										<br/><br/>
										<b>Facial Component</b>
										<br/><br/>
										•	Facial patterns using camera or Kinect like sense detection camera. 
										•	Human behavioral patterns using CCTVs stream. 
										•	Voice and Speaking patterns using Microphone. 
										•	Suspicious transactions using Transaction data/ history and environment/ social factors. 
										<br/><br/>
										Humans can identify or inspect, whether a user is trying to do fraudulent activity or trying to lie by looking at the person. On average people don’t do much better than a coin flip.
										But by using machine learning techniques and algorithms we can automate and increase the accuracy of the detection of fraudulent activities and identify patterns that people normally use for doing fraudulent activities.
										To get the facial data we can use a Kinect camera/ sensor that aim towards the customer’s (user’s) face.

										Using the camera, we can detect
										·         Expressions and Micro-Expressions.
										·         Emotions.
										·         Eye movements.
										·         Nose touching and mouth covering.
										·         Sweating.
										These are some psychological effects when someone tries to hide their true intentions from others or simply when someone tries to do a fraudulent activity.
										By using these data, we can predict or assume whether this user is suspicious or not, with some confidence level. With information that cashier or officer who is doing the transaction can give more attention to the user(customer) and probably reduce or prevent fraudulent activities from happening.
										<br/>
											<br/><br/>
										<b>Body Language Component</b>
										<br/><br/>
										Since the past humans have been able to identify fraudulent activities by looking at another person's body-language and gestures, there are highly paid individuals whose job is to find out those abnormal behavioral patterns. So, in this research part we are trying to automate this process by developing a software solution to identify frauds with human body-languages and abnormal movements using CCTV camera footage. In this research we have decided to use deep learning approach since there might be some social cues we might miss if go with labeling each behavior.
There are three main parts to this sub component
1.       Identifying anomalies.
2.       Creating a risk profile.
3.       Tracking between multiple cameras.
By using this method, we will mainly categorize the persons in the vicinity according to a risk level and those who are with a higher risk level will be analyzed thoroughly by the other components of this research. By doing this we are saving the computational power wastage of analyzing every single person in detail who enters the vicinity.
									</p>
										<br/><br/>
										<b>Voice Component</b>
										<br/><br/>
									<p>
									Like human able identify frauds, lies, deceits or scams by another person’s voice or speaking patterns This product is able to identify lies and fraudulent activities. Mainly there are two types of methods to identify frauds using the voice. Those types are, Language Based & Sounds Based. Since language-based type depend on specific language it cannot be implemented for Sri Lanka, because identifying meaning of Sinhala speeches are quite bigger domain. So, the target is to identify deceits with sounds based.
									<p/>
									<p>
										Sound based frauds detecting also focused on key points and rules based (Based on psychological studies) Key points of sound-based frauds detecting are changes of breathing, changes voice frequencies, stammer, stutter, frequently pausing, repeating,volume and the tone of voice, vocal expression of emotions (screaming, yelling, whining and crying) etc.
Since this product will be working on crowded environment before analyzing the sound clip we have to preprocess the sound clip by cancelling the background noises and identify isolated customer voice with fine details of the sound. Then trained neural network model able to analyze the sound clip and able to detect lies, this part of the solution can state a prediction for suspicion of certain customer by their voice.  Overall flow shown in Figure 4: Voice Capture
									</p>
										<br/><br/>
										<b>Transaction Component</b>
										<br/><br/>
									<p>
										To identify the transactions of a fraudster, a trained machine learning model is needed. Training this model is done by using data sets which are labelled. To select a suitable machine learning algorithm, we have to test by trying out different algorithms. After training the model, it is used by the front end angular component to predict the reliability of a transaction.

As the first step, it is necessary to find a suitable dataset to train the transaction model. It is very rare to find actual transaction details online because of the security and confidentiality reasons. One actual dataset available is the credit card fraud detection data set in kaggle. [10] But as the description of the dataset say, it is a set of anonymized transactions. Because of that, there are no column descriptions for the dataset. This does not matter when the machine learning model is trained. But when a real world scenario is applied to this model, we can not determine which data we have to supply to the model to get a prediction. Because of that reason, we have used a synthetic financial dataset to detect fraudulent transactions. [11] It has generated the transaction using a simulator called PaySim. PaySim uses aggregated data from the private dataset to generate a synthetic dataset that resembles the normal operation of transactions and injects malicious behaviour to later evaluate the performance of fraud detection methods.

The main problem in a fraudulent transaction data set is it is extremely unbalanced. When there are 284315 number of genuine transactions in the set, there are only 492 fraudulent transactions. This leads to a bias of the classification model. To overcome and unbalanced dataset, techniques can be used ie: oversampling, undersampling, SMOTE (Synthetic Minority Oversampling Technique).  SMOTE randomly creates synthetic records to oversample the dataset hence balancing the fraudulent and genuine transaction record numbers.

For the training of the machine learning model, logistic regression algorithm was used. Logistic regression is mostly used for classification problems ie: final oupt is a Yes or No. In this case, Fraudulent or Genuine will be the output.

After training the model, there should be a way to persist the model for future use without having to retrain. A package called Joblib is used to do this task. joblib.dump persist an arbitrary Python object into one file. After dumping the model, it can be hosted in an api using flask (exposing the endpoint).
access from frontend
									</p>

									<h4>Technologies Used</h4>
									<p>Below technologies were used in the transaction module implementation.<br/><br/>
1. Angular JS<br/>
2. Python<br/>
3. Jupyter Notebook<br/>
4. Flask<br/><br/>

When the bank customer comes into the counter, the cashier has to enter the details into the application. The front end of the application is developed using angular js because of the efficiency of development and usage. After the details are entered, these details are validated (field validation). After this phase, the data is flown to the flask endpoint exposed in the backend. The trained machine learning model is served at this backend in a python script. The details sent to this endpoint is received and entered into the machine learning model to predict whether these details show a possible fraudulent behaviour. After the prediction is done, the result is sent as a string value to the front end. Based on the return string value, the cashier will be notified whether this is a possible fraud or not.
</p>

									<hr />
									</section>
					</article>

				<!-- Footer -->
					<footer id="footer">
						<ul class="icons">
							<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
							<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
							<li><a href="#" class="icon brands fa-dribbble"><span class="label">Dribbble</span></a></li>
							<li><a href="#" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
						</ul>
						<ul class="copyright">
							<li>&copy; Untitled</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						</ul>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>